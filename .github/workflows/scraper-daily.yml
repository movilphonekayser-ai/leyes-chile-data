name: Scraper Diario Parlamentario

on:
  schedule:
    - cron: '0 8 * * *'  # Ejecutar diario a las 8 AM UTC
  workflow_dispatch:      # Permite ejecuci√≥n manual

permissions:
  contents: write        # ‚Üê A√ëADIDO: Da permisos de escritura al workflow

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout c√≥digo
      uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}  # ‚Üê A√ëADIDO: Token para permisos
        
    - name: Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
        
    - name: Instalar dependencias
      run: |
        cd scrapers
        pip install -r requirements.txt
        
    - name: Ejecutar scrapers
      run: |
        cd scrapers
        python diputados_basico.py || exit 1

    - name: Verificar que se crearon archivos
      run: |
        ls -la data/ || exit 1
        test -f data/diputados.json || exit 1
        
    - name: Subir cambios a repo
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}  # ‚Üê A√ëADIDO: Variable de entorno
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/
        git commit -m "üìä Actualizaci√≥n autom√°tica de datos parlamentarios $(date '+%Y-%m-%d %H:%M')" || exit 0
        git push
        
    - name: Subir datos a AeonFree via FTP
      uses: SamKirkland/FTP-Deploy-Action@v4.3.4
      with:
        server: ${{ secrets.FTP_SERVER }}
        username: ${{ secrets.FTP_USERNAME }}
        password: ${{ secrets.FTP_PASSWORD }}
        local-dir: ./data/
        server-dir: /web/data/
        exclude: |
          **/.git*
          **/.git*/**
          **/node_modules/**
          **/.env
        dangerous-clean-slate: false
